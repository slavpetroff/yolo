---
phase: "02"
plan: "01"
title: "Two-stage QA gate in execute protocol"
wave: 1
depends_on: []
must_haves:
  - "Step 3d spawns yolo-qa agent after CLI commands collect structured data"
  - "CLI commands remain as data sources (not verdict sources)"
  - "Agent QA REPORT replaces CLI aggregation as the gate verdict"
  - "Feedback loop re-verification spawns QA agent (not just re-runs CLI)"
  - "Fallback to CLI-only aggregation if agent spawn fails"
  - "Step 3d heading removes misleading (optional) label"
---

## Tasks

### Task 1: Rewrite Step 3d with two-stage QA and fix heading

**Files:** `skills/execute-protocol/SKILL.md`

Rewrite the Step 3d section (lines 677-905) to implement two-stage QA verification. Also fix the heading per REQ-04.

**Heading fix (REQ-04):**
Change `### Step 3d: QA gate verification (optional)` to `### Step 3d: QA gate verification`. The "(optional)" label is misleading when `qa_gate="always"`. The activation logic and "When inactive" display already handle skip behavior.

**Two-stage QA structure:**

After reading `qa_gate` config and determining the gate is active, add QA agent model resolution before the verification section:

```bash
QA_MODEL=$("$HOME/.cargo/bin/yolo" resolve-model qa .yolo-planning/config.json ${CLAUDE_PLUGIN_ROOT}/config/model-profiles.json)
if [ $? -ne 0 ]; then echo "$QA_MODEL" >&2; QA_MODEL=""; fi
QA_MAX_TURNS=$("$HOME/.cargo/bin/yolo" resolve-turns qa .yolo-planning/config.json "{effort}")
if [ $? -ne 0 ]; then QA_MAX_TURNS=25; fi
```

**Stage 1 -- CLI data collection (existing commands, unchanged purpose):**
- Keep ALL 5 existing CLI commands (`verify-plan-completion`, `commit-lint`, `diff-against-plan`, `validate-requirements`, `check-regression`) as data collectors
- Run them exactly as today, capturing exit codes and JSON output
- Aggregate results into `CLI_QA_REPORT` JSON (same structure as current `QA_REPORT`)
- **Fast-path optimization:** If ALL 5 commands pass (exit 0), skip agent spawn entirely. Display `Pass (CLI)` and proceed. Agent adds value on failures, not on clean passes.
- If ANY command fails: proceed to Stage 2

**Stage 2 -- QA agent spawn (new):**
- Spawn `yolo-qa` agent via Task tool with `subagent_type: "yolo:yolo-qa"`
- Pass the plan path, summary path, phase directory, and ALL CLI command outputs as structured data
- The agent runs its Core Protocol: reads SUMMARY.md, cross-references CLI findings with actual codebase, performs adversarial verification
- Parse the agent's completion message for the structured `QA REPORT:` block
- The agent's REPORT becomes the gate verdict (not the CLI aggregation)

**Agent spawn template (initial QA):**
```
subject: "QA verification for plan {NN-MM}"
description: |
  {EXECUTION_CONTEXT}

  Verify this plan's delivery adversarially.

  **Plan path:** {plan_path}
  **Summary path:** {summary_path}
  **Phase directory:** {phase_dir}

  **CLI verification results (Stage 1 data):**
  {CLI_QA_REPORT}

  Follow your Core Protocol:
  1. Read SUMMARY.md files from the completed plan directory
  2. Cross-reference CLI findings with actual codebase
  3. Run verification commands yourself if you need additional data
  4. Analyze adversarially — verify claims, check for subtle issues
  5. Produce structured QA REPORT

activeForm: "QA verifying plan {NN-MM}"
model: "${QA_MODEL}"
maxTurns: ${QA_MAX_TURNS}
subagent_type: "yolo:yolo-qa"
```

**Report parsing from agent output:**
- Extract `QA REPORT:` block from agent completion message
- Parse `passed:`, `remediation_eligible:`, `checks:`, `hard_stop_reasons:`, `dev_fixable_failures:` fields
- Convert checks into JSON array matching existing `QA_REPORT.checks[]` format: `{"name": "...", "status": "pass|fail", "evidence": "...", "fixable_by": "dev|architect|manual"}`
- Agent can override CLI `fixable_by` classification (agent has more context from codebase cross-referencing)
- If parsing fails (agent didn't follow format): treat as if agent returned CLI results unchanged, with a warning about unparseable report

```bash
# Extract QA REPORT block from agent completion
AGENT_PASSED=$(echo "$AGENT_OUTPUT" | grep -oP '(?<=passed:\s)(true|false)' | head -1)
AGENT_REMEDIATION=$(echo "$AGENT_OUTPUT" | grep -oP '(?<=remediation_eligible:\s)(true|false)' | head -1)
AGENT_HARD_STOPS=$(echo "$AGENT_OUTPUT" | sed -n '/^hard_stop_reasons:/,/^[a-z_]*:/p' | tail -n +2 | head -n -1)
AGENT_CHECKS_RAW=$(echo "$AGENT_OUTPUT" | sed -n '/^checks:/,/^hard_stop_reasons:/p' | tail -n +2 | head -n -1)
# Parse checks into JSON
QA_REPORT=$(echo "$AGENT_CHECKS_RAW" | while IFS= read -r line; do
  echo "$line" | sed -n 's/- name: \([^ ]*\) | status: \([^ ]*\) | fixable_by: \([^ ]*\).*/{"name":"\1","status":"\2","fixable_by":"\3"}/p'
done | jq -s '{passed: '"${AGENT_PASSED:-false}"', remediation_eligible: '"${AGENT_REMEDIATION:-false}"', checks: .}')
# Fallback if parsing fails
if [ -z "$AGENT_PASSED" ]; then
  echo "Warning: QA agent report unparseable — using CLI results"
  QA_REPORT="$CLI_QA_REPORT"
fi
```

**Agent spawn fallback:**
- If agent spawn fails (Task tool error, timeout, no completion): fall back to CLI-only aggregation
- Display: `Warning: QA agent unavailable -- falling back to CLI verification for plan {NN-MM}`
- Log: `"$HOME/.cargo/bin/yolo" log-event qa_agent_fallback {phase} plan={NN-MM} reason={error} 2>/dev/null || true`
- Use the CLI aggregation from Stage 1 as the gate verdict: `QA_REPORT="$CLI_QA_REPORT"`

**Verdict handling after two-stage:**
- Use `QA_REPORT` (from agent or fallback) for all downstream logic
- Existing ALL-pass / HARD-STOP / Dev-fixable branching logic works unchanged
- The `fixable_by` field in `QA_REPORT.checks[]` now comes from the agent (or CLI on fallback)

**Acceptance criteria:**
- Step 3d heading reads `### Step 3d: QA gate verification` (no parenthetical)
- When `qa_gate="always"`, every plan triggers Stage 1 (CLI) then conditionally Stage 2 (agent)
- All 5 CLI commands still run as data collectors
- CLI all-pass short-circuits without agent spawn (token optimization)
- Agent QA REPORT drives the pass/HARD-STOP/remediation logic
- Agent can override CLI fixable_by classifications
- Agent spawn failure degrades to CLI-only (never breaks the gate)
- All existing execution-state tracking, event logging, and display messages work unchanged

### Task 2: Wire QA agent into the feedback loop re-verification step

**Files:** `skills/execute-protocol/SKILL.md`

Update the QA feedback loop (step e, delta re-run) so re-verification also uses two-stage QA:

**In step e (delta re-run optimization, lines 843-855):**
After Dev completes remediation, the re-verification currently runs only the CLI commands on previously failed checks. Change it to:

1. Run CLI commands on previously failed checks (same delta optimization as today)
2. If ANY re-run check still fails, spawn QA agent with delta context
3. Agent's REPORT drives the loop continue/exit logic

**Re-verification agent spawn (cycle > 1) template:**
```
subject: "QA re-verification for plan {NN-MM} (cycle {QA_CYCLE})"
description: |
  {EXECUTION_CONTEXT}

  Re-verify this plan after Dev remediation (QA feedback loop cycle {QA_CYCLE}/{QA_MAX_CYCLES}).

  **Plan path:** {plan_path}
  **Summary path:** {summary_path}
  **Phase directory:** {phase_dir}
  **QA cycle:** {QA_CYCLE} of {QA_MAX_CYCLES}

  **CLI re-run results (delta -- only previously-failed checks):**
  {CLI_RERUN_REPORT}

  **Previous cycle failures:**
  {PREVIOUS_FAILED_CHECKS}

  Follow Delta Re-run protocol:
  1. Review CLI re-run results for previously-failed checks
  2. Cross-reference any remaining failures with codebase
  3. Check that Dev's fixes didn't introduce NEW failures
  4. Classify: resolved, persistent, new
  5. Produce structured QA REPORT with delta annotations

activeForm: "QA re-verifying plan {NN-MM} (cycle {QA_CYCLE})"
model: "${QA_MODEL}"
maxTurns: ${QA_MAX_TURNS}
subagent_type: "yolo:yolo-qa"
```

**Parsing re-verification output:**
- Same report parsing as initial QA
- Map agent checks to JSON for `FAILED_CHECKS` / `PASSED_CHECKS` update
- Existing delta re-run optimization (skip passed checks) works unchanged
- Execution-state tracking uses agent report data

**Fast-path on re-verification:**
- If ALL re-run CLI checks pass (exit 0): skip agent spawn. All failures resolved by Dev. Exit loop.
- Only spawn agent if ANY re-run check still fails (agent adds value on ambiguous/persistent failures)

**Fallback on re-verification:**
- Same fallback pattern: if agent spawn fails, use CLI re-run results
- Log: `"$HOME/.cargo/bin/yolo" log-event qa_agent_fallback {phase} plan={NN-MM} cycle=${QA_CYCLE} reason={error} 2>/dev/null || true`
- Use: `QA_REPORT="$CLI_RERUN_REPORT"`

**Acceptance criteria:**
- Re-verification cycles spawn the QA agent when CLI checks still fail
- Delta CLI results from previous cycles are passed to the QA agent
- Agent REPORT drives the loop continue/exit logic
- Fast-path: all CLI re-runs pass -> skip agent, exit loop immediately
- Execution-state tracking uses agent report data
- Fallback to CLI works on re-verification cycles too
- All existing loop infrastructure (cycle counting, max cycles, delta re-run optimization, Dev remediation context scoping) works unchanged
